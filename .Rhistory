# alpha density
dalpha_marg <- function(alpha, beta, theta_mat, iteration){
# browser()
density <- alpha^(0.01-1)*exp(-0.01*alpha)
term <- 0
for (i in 1:10){
# density <- density*((gamma(alpha + beta) / gamma(alpha))*theta_mat[i, iteration]^(alpha-1))
term <- term + lgamma(alpha + beta) - lgamma(alpha) + (alpha-1)*log(theta_mat[iteration, i])
}
# return(density)
return(density*exp(term))
}
# beta density
dbeta_marg <- function(alpha, beta, theta_mat, iteration){
density <- beta^(0.01-1)*exp(-0.01*beta)
term <- 0
for (i in 1:10){
# density <- density*((gamma(alpha + beta) / gamma(beta))*(1 - theta_mat[i, iteration])^(beta-1))
term <- term + lgamma(alpha + beta) - lgamma(beta) + (beta-1)*log(1 - theta_mat[iteration, i])
}
# return(density)
return(density*exp(term))
}
# Initialize
alphas[1] <- 1
betas[1] <- 1
thetas[1,] <- rep(0.5, 10)
for (i in 2:n){
# browser()
# Update thetas
for (j in 1:10){
thetas[i,j] <- rbeta(1, alphas[i-1] + traffic$bikes[j], betas[i-1] + traffic$other[j])
}
# Update alpha
alpha_star <- rgamma(1, shape = alphas[i-1], rate = 1)
alpha_accept_prob <- min(1, (dalpha_marg(alpha_star, betas[i-1], thetas, i)*alpha_prop(alpha_star)) /
(dalpha_marg(alphas[i-1], betas[i-1], thetas, i)*alpha_prop(alphas[i-1])))
# browser()
if (runif(1) < alpha_accept_prob){
alphas[i] <- alpha_star
} else {
alphas[i] <- alphas[i-1]
}
# Update beta
beta_star <- rgamma(1, shape = 1, rate = 1/betas[i-1])
beta_accept_prob <- min(1, (dalpha_marg(alphas[i], beta_star, thetas, i)*beta_prop(beta_star)) /
(dalpha_marg(alphas[i], betas[i-1], thetas, i)*beta_prop(betas[i-1])))
if (runif(1) < beta_accept_prob){
betas[i] <- beta_star
} else {
betas[i] <- betas[i-1]
}
}
lgamma(0)
# Metropolis Hastings with Gibbs
n <- 10000                  # Num reps
alphas <- rep(NA, n)        # alphas
betas <- rep(NA, n)         # betas
thetas <- rep(NA, n * 10)   # thetas
dim(thetas) <- c(n, 10)     # theta dimension
#alpha proposal
alpha_prop <- function(x){
dgamma(x, shape = x, rate = 1)
}
# beta proposal
beta_prop <- function(x){
dgamma(x, shape = 1, rate = 1/x)
}
# alpha density
dalpha_marg <- function(alpha, beta, theta_mat, iteration){
# browser()
density <- alpha^(0.01-1)*exp(-0.01*alpha)
term <- 0
for (i in 1:10){
# density <- density*((gamma(alpha + beta) / gamma(alpha))*theta_mat[i, iteration]^(alpha-1))
term <- term + lgamma(alpha + beta) - lgamma(alpha) + (alpha-1)*log(theta_mat[iteration, i])
}
# return(density)
return(density*exp(term))
}
# beta density
dbeta_marg <- function(alpha, beta, theta_mat, iteration){
density <- beta^(0.01-1)*exp(-0.01*beta)
term <- 0
for (i in 1:10){
# density <- density*((gamma(alpha + beta) / gamma(beta))*(1 - theta_mat[i, iteration])^(beta-1))
term <- term + lgamma(alpha + beta) - lgamma(beta) + (beta-1)*log(1 - theta_mat[iteration, i])
}
# return(density)
return(density*exp(term))
}
# Initialize
alphas[1] <- 1
betas[1] <- 1
thetas[1,] <- rep(0.5, 10)
for (i in 2:n){
print(i)
# browser()
# Update thetas
for (j in 1:10){
thetas[i,j] <- rbeta(1, alphas[i-1] + traffic$bikes[j], betas[i-1] + traffic$other[j])
}
# Update alpha
alpha_star <- rgamma(1, shape = alphas[i-1], rate = 1)
alpha_accept_prob <- min(1, (dalpha_marg(alpha_star, betas[i-1], thetas, i)*alpha_prop(alpha_star)) /
(dalpha_marg(alphas[i-1], betas[i-1], thetas, i)*alpha_prop(alphas[i-1])))
# browser()
if (runif(1) < alpha_accept_prob){
alphas[i] <- alpha_star
} else {
alphas[i] <- alphas[i-1]
}
# Update beta
beta_star <- rgamma(1, shape = 1, rate = 1/betas[i-1])
beta_accept_prob <- min(1, (dalpha_marg(alphas[i], beta_star, thetas, i)*beta_prop(beta_star)) /
(dalpha_marg(alphas[i], betas[i-1], thetas, i)*beta_prop(betas[i-1])))
if (runif(1) < beta_accept_prob){
betas[i] <- beta_star
} else {
betas[i] <- betas[i-1]
}
}
# Metropolis Hastings with Gibbs
n <- 10000                  # Num reps
alphas <- rep(NA, n)        # alphas
betas <- rep(NA, n)         # betas
thetas <- rep(NA, n * 10)   # thetas
dim(thetas) <- c(n, 10)     # theta dimension
#alpha proposal
alpha_prop <- function(x){
dgamma(x, shape = x, rate = 1)
}
# beta proposal
beta_prop <- function(x){
dgamma(x, shape = 1, rate = 1/x)
}
# alpha density
dalpha_marg <- function(alpha, beta, theta_mat, iteration){
# browser()
density <- alpha^(0.01-1)*exp(-0.01*alpha)
term <- 0
for (i in 1:10){
# density <- density*((gamma(alpha + beta) / gamma(alpha))*theta_mat[i, iteration]^(alpha-1))
term <- term + lgamma(alpha + beta) - lgamma(alpha) + (alpha-1)*log(theta_mat[iteration, i])
}
# return(density)
return(density*exp(term))
}
# beta density
dbeta_marg <- function(alpha, beta, theta_mat, iteration){
density <- beta^(0.01-1)*exp(-0.01*beta)
term <- 0
for (i in 1:10){
# density <- density*((gamma(alpha + beta) / gamma(beta))*(1 - theta_mat[i, iteration])^(beta-1))
term <- term + lgamma(alpha + beta) - lgamma(beta) + (beta-1)*log(1 - theta_mat[iteration, i])
}
# return(density)
return(density*exp(term))
}
# Initialize
alphas[1] <- 1
betas[1] <- 1
thetas[1,] <- rep(0.5, 10)
for (i in 2:n){
print(i)
# browser()
# Update thetas
for (j in 1:10){
thetas[i,j] <- rbeta(1, alphas[i-1] + traffic$bikes[j], betas[i-1] + traffic$other[j])
}
# Update alpha
alpha_star <- rgamma(1, shape = alphas[i-1], rate = 1)
alpha_accept_prob <- min(1, (dalpha_marg(alpha_star, betas[i-1], thetas, i)*alpha_prop(alpha_star)) /
(dalpha_marg(alphas[i-1], betas[i-1], thetas, i)*alpha_prop(alphas[i-1])))
browser()
if (runif(1) < alpha_accept_prob){
alphas[i] <- alpha_star
} else {
alphas[i] <- alphas[i-1]
}
# Update beta
beta_star <- rgamma(1, shape = 1, rate = 1/betas[i-1])
beta_accept_prob <- min(1, (dalpha_marg(alphas[i], beta_star, thetas, i)*beta_prop(beta_star)) /
(dalpha_marg(alphas[i], betas[i-1], thetas, i)*beta_prop(betas[i-1])))
browser()
if (runif(1) < beta_accept_prob){
betas[i] <- beta_star
} else {
betas[i] <- betas[i-1]
}
}
?browser
head(thetas)
head(thetas, 10)
head(alphas, 10)
head(betas, 10)
# Metropolis Hastings with Gibbs
n <- 10000                  # Num reps
alphas <- rep(NA, n)        # alphas
betas <- rep(NA, n)         # betas
thetas <- rep(NA, n * 10)   # thetas
dim(thetas) <- c(n, 10)     # theta dimension
#alpha proposal
alpha_prop <- function(x){
dgamma(x, shape = x, rate = 1)
}
# beta proposal
beta_prop <- function(x){
dgamma(x, shape = 1, rate = 1/x)
}
# alpha density
dalpha_marg <- function(alpha, beta, theta_mat, iteration){
# browser()
density <- alpha^(0.01-1)*exp(-0.01*alpha)
term <- 0
for (i in 1:10){
# density <- density*((gamma(alpha + beta) / gamma(alpha))*theta_mat[i, iteration]^(alpha-1))
term <- term + lgamma(alpha + beta) - lgamma(alpha) + (alpha-1)*log(theta_mat[iteration, i])
}
# return(density)
return(density*exp(term))
}
# beta density
dbeta_marg <- function(alpha, beta, theta_mat, iteration){
density <- beta^(0.01-1)*exp(-0.01*beta)
term <- 0
for (i in 1:10){
# density <- density*((gamma(alpha + beta) / gamma(beta))*(1 - theta_mat[i, iteration])^(beta-1))
term <- term + lgamma(alpha + beta) - lgamma(beta) + (beta-1)*log(1 - theta_mat[iteration, i])
}
# return(density)
return(density*exp(term))
}
# Initialize
alphas[1] <- 4
betas[1] <- 4
thetas[1,] <- rep(0.5, 10)
for (i in 2:n){
print(i)
# browser()
# Update thetas
for (j in 1:10){
thetas[i,j] <- rbeta(1, alphas[i-1] + traffic$bikes[j], betas[i-1] + traffic$other[j])
}
# Update alpha
alpha_star <- rgamma(1, shape = alphas[i-1], rate = 1)
alpha_accept_prob <- min(1, (dalpha_marg(alpha_star, betas[i-1], thetas, i)*alpha_prop(alpha_star)) /
(dalpha_marg(alphas[i-1], betas[i-1], thetas, i)*alpha_prop(alphas[i-1])))
browser()
if (runif(1) < alpha_accept_prob){
alphas[i] <- alpha_star
} else {
alphas[i] <- alphas[i-1]
}
# Update beta
beta_star <- rgamma(1, shape = 1, rate = 1/betas[i-1])
beta_accept_prob <- min(1, (dalpha_marg(alphas[i], beta_star, thetas, i)*beta_prop(beta_star)) /
(dalpha_marg(alphas[i], betas[i-1], thetas, i)*beta_prop(betas[i-1])))
browser()
if (runif(1) < beta_accept_prob){
betas[i] <- beta_star
} else {
betas[i] <- betas[i-1]
}
}
head(alphas)
head(betas)
head(thetas)
head(alpha, 10)
head(alphas, 10)
head(betas, 10)
library(dplyr)
?count
library("Lahmna")
install.packages("Lahman")
library(Lahmna)
library(Lahmnan)
library(Lahman)
?Lahman
install.packages("rstudioapi")
quit
library(devtools)
devtools::create("C:/Users/zkeller/Google_Drive/stats_701/final_project/recipefindr")
devtools::create("C:/Users/zkeller/Google_Drive/stats_701/final_project/sim701")
data(wage)
install.packages("ISLR")
library(ISLR)
?ISLR
data(wage)
data(WAGE)
?ISLR
ISLR::Wage
data(Wage)
?Wage
head(Wage)
dim(Wage)
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
data("College")
head(College)
?College
fix(College)
college <- College # they use lower case but in the package it is upper
college$Elite <- as.factor(ifelse(college$Top10perc > 50, "Yes", "No"))
summary(college$Elite)
plot(college$Elite, college$Outstate)
plot(college$Elite, college$Outstate)
library(ggplot2)
str(college)
qplot(college$Grad.Rate)
qplot(college$perc.alumni)
qplot(college$Grad.Rate, college$perc.alumni)
library(plots250)
?pval
?glm
GGally::ggpairs(iris)
GGally::ggpairs(iris[, 1:4])
GGally::ggpairs(log(iris[, 1:4]))
data("iris")
ir.pca <- prcomp(log.ir,
center = TRUE,
scale. = TRUE)
data("iris")
log.ir <- log(iris[, 1:4])
ir.species <- iris[, 5]
ir.pca <- prcomp(log.ir,
center = TRUE,
scale. = TRUE)
?prcomp
ir.pca
plot(ir.pca, type = "l")
summary(ir.pca)
predict(i.rpca, newdata = trail(log.ir, 2))
predict(ir.pca, newdata = trail(log.ir, 2))
predict(ir.pca, newdata = tail(log.ir, 2))
library(ggbiplot)
devtools::install_github("ggbiplot", "vqv")
devtools::install_github("vqv/ggbiplot")
library(caret)
biplot(ir.pca)
biplot(ir.pca, col = ir.species)
?biplot
devtools::install_github("vqv/ggbiplot")
install.packages("caret")
data(Boston)
library(ISLR)
data(Boston)
?ISLR
data(Auto)
names(Auto)
?step
lm.fit <- lm(mpg ~ .-name, data = Auto)
step(lm.fit)
data(swiss)
example(lm)
names(boston)
names(Boston)
names(Auto)
step(lm(mpg ~ cylinders, data = Auto))
?step
lm.fit <- lm(mpg ~ .-name, data = Auto)
step(lm.fit)
lm.fit2 <- step(lm.fit)
lm.fit
lm.fit2
summary(lm.fit2)
library(ISLR)
data("Smarket")
knitr::opts_chunk$set(echo = TRUE)
glm.fit <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
data = Smarket,
family = binomial)
glm.fit <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
data = Smarket,
family = "binomial")
summary(glm.fit)
coef(glm.fit)
summary(glm.fit)$coef
summary(glm.fit)$coef[, 4]
glm.probs <- predict(glm.fit, type = "response")
glm.probs[1:10]
contrasts(glm.fit)
?contrasts
contrasts(Smarket$Direction)
glm.pred <- rep("Down", 1250)
glm.pred[glm.robs > 0.5] = "Up"
glm.pred[glm.probs > 0.5] = "Up"
glm.pred[glm.probs > 0.5] <- "Up"
table(glm.pred, Smarket$Direction)
(507 + 145) / 1250
mean(glm.pred == Smarket$Direction)
train <- Smarket$Year < 2005
Smarket.2005 <- Smarket[!train, ]
dim(Smarket.2005)
Direction.2005 <- Smarket$Direction[!train]
glm.fit <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
data = Smarket,
family = "binomial",
subset = train)
glm.probs = predict(glm.fit, Smarket.2005, type = "response")
glm.pred <- rep("Down", 252)
glm.pred[glm.probs > 0.5] <- "Up"
table(glm.pred, Direction.2005)
mean(glm.pred == Direction.2005)
glm.fit <- glm(Direction~Lag1+Lag2, data = Smarket, family = "binomial", subset = train)
glm.probs <- predict(glm.fit, Smarket.2005, type = "response")
glm.pred <- rep("Down", 252)
glm.pred[glm.probs > 0.5] <- "Up"
table(glm.pred, Direction.2005)
106/(106+76)
predict(glm.fit, newdata = data.frame(Lag1 = c(1.2, 1.5), Lag2 = c(1.1, -0.8)), type = "response")
lda.fit <- lda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)
library(MASS)
lda.fit <- lda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)
?MASS
?lda
lda.fit
plot(lda.fit)
lda.fit
plot(lda.fit)
lda.pred <- predict(lda.fit, Smarket.2005)
names(lda.pred)
lda.class <- lda.pred$class
table(lda.class, Direction.2005)
mean(lda.class == Direction.2005)
sum(lda.pred$posterior[, 1] >= 0.5)
sum(lda.pred$posterior[, 1] < 0.5)
lda.pred$posterior[1:10, 1]
lda.class[1:20]
qda.fit <- qda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)
qda.fit
qda.class <- predict(qda.fit, Smarket.2005)$class
table(qda.class, Direction.2005)
mean(qda.class == Direction.2005)
library(class)
?class
train.X <- cbind(Lag1, lag2)[train, ]
library(class)
test.X <- cbind(Smarket$Lag1, Smarket$Lag2)[!train, ]
train.Dreiction <- Smarket$Direction[train]
set.seed(1)
knn.pred <- knn(train.X, test.X, train.Dreiction, k = 1)
train.X <- cbind(Smarket$Lag1, Smarket$Lag2)[train, ]
test.X <- cbind(Smarket$Lag1, Smarket$Lag2)[!train, ]
train.Dreiction <- Smarket$Direction[train]
knn.pred <- knn(train.X, test.X, train.Dreiction, k = 1)
table(knn.pred, Direction.2005)
(83+43)/252
knn.pred <- knn(train.X, test.X, train.Dire , k = 3)
train.Direction <- Smarket$Direction[train]
knn.pred <- knn(train.X, test.X, train.Direction , k = 3)
table(knn.pred, Direction.2005)
# k = 1
knn.pred <- knn(train.X, test.X, train.Direction, k = 1)
table(knn.pred, Direction.2005)
(83+43)/252
# k = 3
knn.pred <- knn(train.X, test.X, train.Direction , k = 3)
table(knn.pred, Direction.2005)
data("Caravan")
summary(Caravan$Purchase)
348/5822
std.X <- scale(Caravan[, -86]) # col 86 is qualitative
var(Caravan[, 1])
var(Caravan[, 2])
var(std.X[, 1])
var(std.X[, 2])
std.X <- scale(Caravan[, -86]) # col 86 is qualitative
var(Caravan[, 1])
var(Caravan[, 2])
var(std.X[, 1])
var(std.X[, 2])
# split into training and test data set
test <- 1:1000
train.X <- std.X[-test, ]
test.X <- std.X[test, ]
train.Y <- Caravan$Purchase[-test]
test.Y <- Caravan$Purchase[test]
set.seed(1)
knn.pred <- knn(train.X, test.X, train.Y, k=1)
mean(test.Y != knn.pred)
mean(test.Y != "no")
mean(test.Y != "No")
?knn
table(knn.pred, test.Y)
9/(68+9)
knn.pred <- knn(train.X, test.X, train.Y, k = 3)
table(knn.pred, test.Y)
5/26
knn.pred <- knn(train.X, test.X, train.Y, k = 5)
table(knn.pred, test.Y)
4/15
glm.fit <- glm(Purchase ~ ., data = Caravan, family = binomial, subset = -test)
glm.probs <- predict(glm.fit, Caravan[test, ], type = "response")
glm.pred <- rep("No", 1000)
glm.pred[glm.probs > 0.5] <- "Yes"
table(glm.pred, test.Y)
glm.pred <- rep("No", 1000)
glm.pred[glm.probs > 0.25] = "Yes"
table(glm.pred, test.Y)
options
options()
blogdown::serve_site()
setwd("C:/Users/zkeller/Google_Drive/github_page/website-hugo/")
blogdown::serve_site()
blogdown::build_site()
blogdown::build_site()
library(blogdown)
serve_site()
blogdown::build_site()
serve_site()
build_site()
